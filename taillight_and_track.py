# -*- coding: utf-8 -*-
"""TailLight_and_Track.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OMer_5oNtG8Y4t8E2Xbi-akN8mnEbqpE
"""

!pip install ultralytics

from google.colab import drive
drive.mount('/content/drive')

import shutil
source_path = "/content/drive/My Drive/test.mp4"
destination_path = "/content/"
shutil.copy(source_path, destination_path)

!yolo track source="/content/drive/My Drive/test.mp4" save=True

import cv2
import numpy as np
from ultralytics import YOLO
from collections import defaultdict
from IPython.display import display, HTML

track_history = defaultdict(list)

model = YOLO("yolov8n.pt")
brake_model = YOLO("/content/drive/My Drive/best.pt")
names = model.model.names
brake_names = brake_model.model.names

video_path = "/content/drive/My Drive/test.mp4"
output_path = "/content/drive/My Drive/ggggg.avi"

cap = cv2.VideoCapture(video_path)
assert cap.isOpened(), "Error reading video file"

w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))

fourcc = cv2.VideoWriter_fourcc(*'XVID')
out = cv2.VideoWriter(output_path, fourcc, fps, (w, h))

# Process video frames
while cap.isOpened():
    success, frame = cap.read()
    if success:
        # Perform object tracking
        results = model.track(frame, persist=True, verbose=False)
        brake_results = brake_model(frame)

        boxes = results[0].boxes.xyxy.cpu()
        brake_boxes = brake_results[0].boxes.xyxy.cpu() if brake_results[0].boxes else []

        if results[0].boxes.id is not None:
            # Extract prediction results
            clss = results[0].boxes.cls.cpu().tolist()
            track_ids = results[0].boxes.id.int().cpu().tolist()
            confs = results[0].boxes.conf.float().cpu().tolist()

            for box, cls, track_id in zip(boxes, clss, track_ids):
                # Update tracking history
                track = track_history[track_id]
                track.append((int((box[0] + box[2]) / 2), int((box[1] + box[3]) / 2)))
                if len(track) > 30:
                    track.pop(0)

                # Calculate speed and deviation
                if len(track) >= 2:
                    dx = track[-1][0] - track[-2][0]
                    dy = track[-1][1] - track[-2][1]
                    speed = np.sqrt(dx ** 2 + dy ** 2)
                    deviation = np.sqrt((dx / w) ** 2 + (dy / h) ** 2)
                else:
                    speed = 0
                    deviation = 0

                # Determine line color based on deviation
                line_color = (0, 0, 255) if deviation > 0.01 else (0, 255, 0)

                # Draw bounding box and text
                class_name = names[int(cls)] if 0 <= cls < len(names) else f"Class {cls}"
                cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)
                cv2.putText(frame, f"Class: {class_name}, Speed: {speed:.2f}, Deviation: {deviation:.4f}",
                            (int(box[0]), int(box[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                # Draw tracks
                for i in range(len(track) - 1):
                    cv2.line(frame, track[i], track[i + 1], line_color, 2)

            # Draw brake light detections
            for box in brake_boxes:
                cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 0, 255), 2)
                cv2.putText(frame, "Brake Light", (int(box[0]), int(box[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # Write frame to video
        out.write(frame)

        # Display the frame in Colab
        display_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        display(display_frame)

        # Break on 'q' key press
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break
    else:
        break

# Release video capture and writer
cap.release()
out.release()
cv2.destroyAllWindows()